{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d465cefa40b64186834b3ecb7cb57865":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee677969d09b4d8eba6b69dd1c856460","IPY_MODEL_8195454d50b0478e98bb179072cab378","IPY_MODEL_1e53e20c75104f4f8e0edb2602a66239"],"layout":"IPY_MODEL_149976dacf8a443fa27e56e29d494b6e"}},"ee677969d09b4d8eba6b69dd1c856460":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d3b0adb932c4bf387f8707eb1175518","placeholder":"​","style":"IPY_MODEL_1b961483f9e249cbb85fc230b72e7810","value":"tokenizer_config.json: 100%"}},"8195454d50b0478e98bb179072cab378":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aee1bc6aeb74735862c394a5fba42f0","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a89926397ac5440e893c69f53681cb92","value":28}},"1e53e20c75104f4f8e0edb2602a66239":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2de6f0c736984eccba1aba4f739e9b0d","placeholder":"​","style":"IPY_MODEL_f940ebfe16da49168d66ef75dded1471","value":" 28.0/28.0 [00:00&lt;00:00, 1.97kB/s]"}},"149976dacf8a443fa27e56e29d494b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d3b0adb932c4bf387f8707eb1175518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b961483f9e249cbb85fc230b72e7810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aee1bc6aeb74735862c394a5fba42f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a89926397ac5440e893c69f53681cb92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2de6f0c736984eccba1aba4f739e9b0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f940ebfe16da49168d66ef75dded1471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5312609a32f4e339d0729c483da8251":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_483d34cc49ca49e1a70a190c7a95abf7","IPY_MODEL_2810fe61f287441c8f878c16d0884e7a","IPY_MODEL_e3eb5a59dfb2427e92a86fbc9da6c06c"],"layout":"IPY_MODEL_b926dedf4f6940369b5c5af0ed87c495"}},"483d34cc49ca49e1a70a190c7a95abf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93aa266e64864f55ae808a18aa5c0cdb","placeholder":"​","style":"IPY_MODEL_1b621072403e405c9d45d0c1db4e74be","value":"config.json: 100%"}},"2810fe61f287441c8f878c16d0884e7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44650ea298fa4a9b9114d897841a1849","max":389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f2b61d046ab46d48aaebb6a960c3cee","value":389}},"e3eb5a59dfb2427e92a86fbc9da6c06c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87a91b26d4264324be3a956263a76a9c","placeholder":"​","style":"IPY_MODEL_d50bd60ea4504339b4c064af0f97d3b1","value":" 389/389 [00:00&lt;00:00, 35.5kB/s]"}},"b926dedf4f6940369b5c5af0ed87c495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93aa266e64864f55ae808a18aa5c0cdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b621072403e405c9d45d0c1db4e74be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44650ea298fa4a9b9114d897841a1849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f2b61d046ab46d48aaebb6a960c3cee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87a91b26d4264324be3a956263a76a9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d50bd60ea4504339b4c064af0f97d3b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0b7c8b7157d40e2b1908a0d1c4ef201":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f05bc94bb1b146b0a298fb4604a99688","IPY_MODEL_92bf9653c2c2475f905495ed266422b8","IPY_MODEL_0e1c0354a8e44fd9a39b9f43b90d7e88"],"layout":"IPY_MODEL_23ceaafdc4084b5bbb3071140d3b3fbd"}},"f05bc94bb1b146b0a298fb4604a99688":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce336c2647a84010a6aa2f46cf17757a","placeholder":"​","style":"IPY_MODEL_6b30cd5a3dbc45bd9c6c2aa4cd3ded7c","value":"vocab.txt: 100%"}},"92bf9653c2c2475f905495ed266422b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_580bbacbe4b34ace8a8de2c0819fe182","max":103847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11da50eaf1a84e0292ce0e57ee0d00fe","value":103847}},"0e1c0354a8e44fd9a39b9f43b90d7e88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cef67c120962422895eee952e243bf67","placeholder":"​","style":"IPY_MODEL_8e99d0f6cea844f5ae87bb2290419801","value":" 104k/104k [00:00&lt;00:00, 454kB/s]"}},"23ceaafdc4084b5bbb3071140d3b3fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce336c2647a84010a6aa2f46cf17757a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b30cd5a3dbc45bd9c6c2aa4cd3ded7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"580bbacbe4b34ace8a8de2c0819fe182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11da50eaf1a84e0292ce0e57ee0d00fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cef67c120962422895eee952e243bf67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e99d0f6cea844f5ae87bb2290419801":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66ae33c098d04002b912b0d493dace1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a33b07d372614248b27cd4fba0e6989b","IPY_MODEL_64f48574dc3c4bdca06c9acbb096d77f","IPY_MODEL_ff17bc72d15049b99a38697551b73b5a"],"layout":"IPY_MODEL_10f7806337a84c49906c07e57e2c82dd"}},"a33b07d372614248b27cd4fba0e6989b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4553f783cd984bafab323093b81efd1b","placeholder":"​","style":"IPY_MODEL_bc9aa4598e834341a76602f59908a143","value":"config.json: 100%"}},"64f48574dc3c4bdca06c9acbb096d77f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3092d007bfd34a21a8da66b08fe10ea5","max":679,"min":0,"orientation":"horizontal","style":"IPY_MODEL_651192226e08466a83a9ebd6d6b104a4","value":679}},"ff17bc72d15049b99a38697551b73b5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad626efc94854644a8d682b1e056113e","placeholder":"​","style":"IPY_MODEL_ce10f2542509484ca5c62b463ff7fe90","value":" 679/679 [00:00&lt;00:00, 58.8kB/s]"}},"10f7806337a84c49906c07e57e2c82dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4553f783cd984bafab323093b81efd1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc9aa4598e834341a76602f59908a143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3092d007bfd34a21a8da66b08fe10ea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651192226e08466a83a9ebd6d6b104a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad626efc94854644a8d682b1e056113e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce10f2542509484ca5c62b463ff7fe90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"632d7f79f0b141b48648156af1ea5b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45b9503cb64e4b1bac8b39e2cc03b47b","IPY_MODEL_2f7507c191e54cc2803dbc45a8d1bd73","IPY_MODEL_e5e92c80fde5432398c820600108fc35"],"layout":"IPY_MODEL_2823564c06ee48c1b59a4898520ca2e9"}},"45b9503cb64e4b1bac8b39e2cc03b47b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_438b7761d5154bbeb30f41a355f9fd4c","placeholder":"​","style":"IPY_MODEL_985f56f559874f89b2a3490ed59a6a36","value":"model.safetensors: 100%"}},"2f7507c191e54cc2803dbc45a8d1bd73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcf9300731324b18a6eca6551640a7de","max":394646400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4653221b8a0b4b04a3fe2ac150c8b207","value":394646400}},"e5e92c80fde5432398c820600108fc35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95f483b793884abe9ee2353efee34360","placeholder":"​","style":"IPY_MODEL_e676076a308143fabc27282197856129","value":" 395M/395M [00:02&lt;00:00, 178MB/s]"}},"2823564c06ee48c1b59a4898520ca2e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"438b7761d5154bbeb30f41a355f9fd4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"985f56f559874f89b2a3490ed59a6a36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcf9300731324b18a6eca6551640a7de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4653221b8a0b4b04a3fe2ac150c8b207":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95f483b793884abe9ee2353efee34360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e676076a308143fabc27282197856129":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNULzU9Gw9R7","executionInfo":{"status":"ok","timestamp":1736437941882,"user_tz":-540,"elapsed":22257,"user":{"displayName":"강남대연구실","userId":"13253583547600508252"}},"outputId":"7fce058b-059b-4ad3-e38f-04e931b9d177"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZAOwHKFwom8"},"outputs":[],"source":["import os\n","import gc\n","import json\n","import torch\n","import logging\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from tqdm import tqdm\n","import torch.nn as nn\n","from pathlib import Path\n","from torch.cuda import Event\n","from typing import List, Dict, Tuple\n","from datetime import datetime\n","import torch.distributed as dist\n","from xgboost import XGBClassifier\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.parallel import DistributedDataParallel\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_scheduler, AutoModelForSequenceClassification\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n","from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","import joblib\n","import re"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/데이터/medical_data.csv\", encoding = 'utf-8')\n","df.shape"],"metadata":{"id":"Poz9sAar6nFz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736438057368,"user_tz":-540,"elapsed":1499,"user":{"displayName":"강남대연구실","userId":"13253583547600508252"}},"outputId":"70cfa6ac-a31b-4dc0-a3f7-13b92a33b20d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48915, 11)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# 고도화된 코드"],"metadata":{"id":"xZ27QRrjK8zj"}},{"cell_type":"code","source":["class TextDataset(Dataset):\n","    \"\"\"KM-BERT를 위한 데이터셋\"\"\"\n","    def __init__(self, texts: List[str], labels: np.ndarray,\n","                 tokenizer, max_length=512):\n","        self.texts = texts\n","        self.labels = torch.LongTensor(labels)\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': self.labels[idx]\n","        }"],"metadata":{"id":"Sew2CBbYbR7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class KMBertModel:\n","    \"\"\"KM-BERT 모델 클래스\"\"\"\n","    def __init__(self, num_labels, device='cuda'):\n","        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-BERT-char16424\")\n","        self.model = AutoModelForSequenceClassification.from_pretrained(\"madatnlp/km-bert\",num_labels=num_labels).to(self.device)\n","\n","    # KMBertModel의 train_and_predict 메서드 수정\n","    def train_and_predict(self, train_texts, train_labels, val_texts, val_labels, position = 0):\n","        # 데이터셋 생성\n","        train_dataset = TextDataset(train_texts, train_labels, self.tokenizer)\n","        val_dataset = TextDataset(val_texts, val_labels, self.tokenizer)\n","\n","        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","        val_loader = DataLoader(val_dataset, batch_size=32)\n","\n","        # 학습\n","        optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5)\n","        criterion = nn.CrossEntropyLoss()\n","\n","        for epoch in range(1):\n","            # 학습 루프\n","            self.model.train()\n","            train_pbar = tqdm(train_loader,\n","                     desc=f'Epoch {epoch+1}/5 [Train]',\n","                     leave=True,  # 진행바를 유지\n","                     position=0,   # 진행바 위치\n","                     ncols=100)    # 진행바 길이\n","            total_loss = 0\n","\n","            for batch in train_pbar:\n","                optimizer.zero_grad()\n","                outputs = self.model(\n","                    input_ids=batch['input_ids'].to(self.device),\n","                    attention_mask=batch['attention_mask'].to(self.device)\n","                )\n","                loss = criterion(outputs.logits, batch['labels'].to(self.device))\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss += loss.item()\n","                train_pbar.set_postfix({'loss': f'{total_loss/(train_pbar.n+1):.4f}'})\n","\n","        # 예측\n","        self.model.eval()\n","        predictions = []\n","        val_pbar = tqdm(val_loader,\n","                   desc='Predicting',\n","                   leave=False,     # 이전 진행바 지우기\n","                   position=0,      # 진행바 위치 고정\n","                   ncols=100,       # 진행바 길이 고정\n","                   dynamic_ncols=False  # 동적 길이 조정 비활성화\n","                   )\n","\n","        with torch.no_grad():\n","            for batch in val_pbar:\n","                outputs = self.model(\n","                    input_ids=batch['input_ids'].to(self.device),\n","                    attention_mask=batch['attention_mask'].to(self.device)\n","                )\n","                preds = torch.softmax(outputs.logits, dim=1)\n","                predictions.append(preds.cpu().numpy())\n","\n","        return np.vstack(predictions)"],"metadata":{"id":"-eizrqd-bXVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q catboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXjRdnVA_gL3","executionInfo":{"status":"ok","timestamp":1736438079631,"user_tz":-540,"elapsed":7046,"user":{"displayName":"강남대연구실","userId":"13253583547600508252"}},"outputId":"7ba60728-01c8-4026-f0a9-0898ab321cf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","import lightgbm as lgb\n","from catboost import CatBoostClassifier\n","\n","class TabularModel:\n","    \"\"\"정형 데이터 처리 모델\"\"\"\n","    def __init__(self):\n","        self.models = {\n","            'xgboost': xgb.XGBClassifier(\n","                n_estimators=200,\n","                learning_rate=0.1,\n","                max_depth=7\n","            ),\n","            'lightgbm': lgb.LGBMClassifier(\n","                n_estimators=200,\n","                learning_rate=0.1,\n","                verbose = -1\n","            ),\n","            'catboost': CatBoostClassifier(\n","                iterations=200,\n","                learning_rate=0.1,\n","                verbose=False\n","            )\n","        }\n","        self.encoders = {}\n","        self.scalers = {}\n","\n","    def preprocess(self, data, categorical_cols, numeric_cols, is_training=True):\n","        data = data.copy()\n","\n","        # 수치형 특징 처리\n","        if is_training:\n","            for col in numeric_cols:\n","                self.scalers[col] = StandardScaler()\n","                data[col] = self.scalers[col].fit_transform(data[[col]])\n","        else:\n","            for col in numeric_cols:\n","                data[col] = self.scalers[col].transform(data[[col]])\n","\n","        # 범주형 특징 처리\n","        if is_training:\n","            for col in categorical_cols:\n","                self.encoders[col] = LabelEncoder()\n","                data[col] = self.encoders[col].fit_transform(data[col])\n","        else:\n","            for col in categorical_cols:\n","                data[col] = self.encoders[col].transform(data[col])\n","\n","        return data\n","\n","    # TabularModel의 train_and_predict 메서드 수정\n","    def train_and_predict(self, train_data, train_labels, val_data, position=0):\n","        predictions = {}\n","\n","        # train_labels가 0부터 시작하는 연속된 정수를 갖도록 보장합니다.\n","        unique_labels = np.unique(train_labels)\n","        label_mapping = {label: i for i, label in enumerate(unique_labels)}\n","        train_labels = np.array([label_mapping[label] for label in train_labels])\n","\n","        with tqdm(self.models.items(),\n","                desc=\"모델 학습 중\",\n","                leave=True,\n","                position=0,\n","                ncols=100) as pbar:\n","            for name, model in pbar:\n","                pbar.set_postfix({'model': name})\n","\n","                # 모델이 XGBoost인지 확인하고 목적 함수를 설정합니다.\n","                if name == 'xgboost':\n","                    # 다중 클래스 분류가 필요한지 확인합니다.\n","                    if len(unique_labels) > 2:\n","                        model.set_params(objective='multi:softprob', num_class=len(unique_labels))\n","                    else:\n","                        model.set_params(objective='binary:logistic')\n","\n","                # val_data.index를 사용하는 대신, TwoStagePredictor 클래스의\n","                # _get_tabular_predictions 메서드에 제공된 원래 레이블을 사용합니다.\n","                # 이는 val_data에 대한 레이블이 'labels' 인수로 올바르게 전달되었다고 가정합니다.\n","                val_labels_original = [label for label in val_data.index]\n","                val_labels = np.array([label_mapping.get(label, -1) for label in val_labels_original])\n","\n","                # 레이블이 -1(알 수 없는 레이블)인 행을 필터링합니다.\n","                valid_indices = np.where(val_labels != -1)[0]\n","                val_data_filtered = val_data.iloc[valid_indices]\n","                val_labels_filtered = val_labels[valid_indices]\n","\n","                model.fit(\n","                    train_data,\n","                    train_labels,\n","                    eval_set=[(val_data_filtered, val_labels_filtered)],  # eval_set에 레이블을 포함합니다.\n","\n","                )\n","                predictions[name] = model.predict_proba(val_data)\n","\n","        return np.mean([pred for pred in predictions.values()], axis=0)"],"metadata":{"id":"BAAOenNtbj-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TwoStagePredictor:\n","    \"\"\"2단계 예측 시스템\"\"\"\n","    def __init__(self):\n","        self.stage1_text_model = None  # KM-BERT for 진료과목코드\n","        self.stage1_tabular_model = TabularModel()  # ML models for 진료과목코드\n","        self.stage2_text_model = None  # KM-BERT for 주상병코드\n","        self.stage2_tabular_model = TabularModel()  # ML models for 주상병코드\n","\n","        self.stage1_stacker = xgb.XGBClassifier()  # Stack ensemble for 진료과목코드\n","        self.stage2_stacker = xgb.XGBClassifier()  # Stack ensemble for 주상병코드\n","\n","    def predict(self, df: pd.DataFrame, test_size=0.2):\n","        print(\"\\n=== Stage 1: 진료과목코드 예측 ===\")\n","        train_idx = int(len(df) * (1 - test_size))\n","\n","        # Stage 1 진행바 수정\n","        with tqdm(total=2,\n","                 desc=\"Stage 1 Processing\",\n","                 leave=True,\n","                 position=0,\n","                 ncols=100,\n","                 bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n","                 ) as pbar:\n","            # Text 처리\n","            stage1_text_preds = self._get_text_predictions(\n","                df['증상'].values,\n","                df['진료과목코드'].values,\n","                train_idx,\n","                is_stage1=True,\n","                position=1  # 중첩된 진행바 위치 지정\n","            )\n","            pbar.update(1)\n","\n","            # Tabular 처리\n","            stage1_tabular_preds = self._get_tabular_predictions(\n","                df,\n","                df['진료과목코드'].values,\n","                train_idx,\n","                is_stage1=True,\n","                position=1  # 중첩된 진행바 위치 지정\n","            )\n","            pbar.update(1)\n","\n","        # Stack Ensemble\n","        print(\"Performing Stage 1 Stack Ensemble...\")\n","        stage1_features = np.hstack([stage1_text_preds, stage1_tabular_preds])\n","        self.stage1_stacker.fit(\n","            stage1_features[:train_idx],\n","            df['진료과목코드'].values[:train_idx]\n","        )\n","        stage1_predictions = self.stage1_stacker.predict(stage1_features[train_idx:])\n","\n","        # Stage 1 평가\n","        stage1_metrics = evaluate_multiclass(\n","            df['진료과목코드'].values[train_idx:],\n","            stage1_predictions,\n","            prefix='dept_'\n","        )\n","\n","        print(\"\\n=== Stage 2: 주상병코드 예측 ===\")\n","        # 2단계: 주상병코드 예측\n","        # 1단계 예측 결과를 데이터에 추가\n","        df_stage2 = df.copy()\n","        df_stage2.loc[train_idx:, '진료과목코드'] = stage1_predictions\n","\n","        with tqdm(total=2,\n","                 desc=\"Stage 2 Processing\",\n","                 leave=True,\n","                 position=0,\n","                 ncols=100,\n","                 bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n","                 ) as pbar:\n","            stage2_text_preds = self._get_text_predictions(\n","                df_stage2['증상'].values,\n","                df_stage2['주상병코드'].values,\n","                train_idx,\n","                is_stage1=False,\n","                position=1  # 중첩된 진행바 위치 지정\n","            )\n","            pbar.update(1)\n","\n","            stage2_tabular_preds = self._get_tabular_predictions(\n","                df_stage2,\n","                df_stage2['주상병코드'].values,\n","                train_idx,\n","                is_stage1=False,\n","                position=1  # 중첩된 진행바 위치 지정\n","            )\n","            pbar.update(1)\n","\n","        # Stack Ensemble\n","        print(\"Performing Stage 2 Stack Ensemble...\")\n","        stage2_features = np.hstack([stage2_text_preds, stage2_tabular_preds])\n","        self.stage2_stacker.fit(\n","            stage2_features[:train_idx],\n","            df['주상병코드'].values[:train_idx]\n","        )\n","        stage2_predictions = self.stage2_stacker.predict(stage2_features[train_idx:])\n","\n","        # Stage 2 평가\n","        stage2_metrics = evaluate_multiclass(\n","            df['주상병코드'].values[train_idx:],\n","            stage2_predictions,\n","            prefix='disease_'\n","        )\n","\n","        # 결과 저장 및 분석\n","        results_df, final_metrics = save_and_analyze_results(\n","            df[train_idx:],\n","            stage1_predictions,\n","            stage2_predictions\n","        )\n","\n","        return stage1_predictions, stage2_predictions, stage1_metrics, stage2_metrics\n","\n","    def _get_text_predictions(self, texts, labels, train_idx, is_stage1=True, position=0):\n","        stage_name = \"Stage 1\" if is_stage1 else \"Stage 2\"\n","        print(f\"\\nProcessing {stage_name} Text Data with KM-BERT...\")\n","\n","        num_labels = len(np.unique(labels))\n","        model = KMBertModel(num_labels=num_labels)\n","\n","        return model.train_and_predict(\n","            texts[:train_idx],\n","            labels[:train_idx],\n","            texts[train_idx:],\n","            labels[train_idx:],\n","            position=position  # tqdm 위치 전달\n","        )\n","\n","    def _get_tabular_predictions(self, df, labels, train_idx, is_stage1=True, position=0):\n","        stage_name = \"Stage 1\" if is_stage1 else \"Stage 2\"\n","        print(f\"\\nProcessing {stage_name} Tabular Data...\")\n","\n","        categorical_cols = ['성별코드', '연령대코드']\n","        numeric_cols = ['요양일수', '입내원일수', '총처방일수']\n","\n","        if not is_stage1:\n","            categorical_cols.append('진료과목코드')\n","\n","        model = TabularModel()\n","        processed_data = model.preprocess(\n","            df[categorical_cols + numeric_cols],\n","            categorical_cols,\n","            numeric_cols\n","        )\n","\n","        return model.train_and_predict(\n","            processed_data[:train_idx],\n","            labels[:train_idx],\n","            processed_data[train_idx:],\n","            position=position  # tqdm 위치 전달\n","        )\n","\n","def evaluate_multiclass(y_true, y_pred, prefix=''):\n","    \"\"\"다중분류 평가 메트릭 계산\"\"\"\n","    return {\n","        f'{prefix}accuracy': accuracy_score(y_true, y_pred),\n","        f'{prefix}macro_f1': f1_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_f1': f1_score(y_true, y_pred, average='weighted'),\n","        f'{prefix}macro_precision': precision_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_precision': precision_score(y_true, y_pred, average='weighted'),\n","        f'{prefix}macro_recall': recall_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_recall': recall_score(y_true, y_pred, average='weighted')\n","    }\n","\n","def save_and_analyze_results(test_df, dept_predictions, disease_predictions):\n","    \"\"\"예측 결과 저장 및 분석\"\"\"\n","    results_df = pd.DataFrame({\n","        'Original_Dept': test_df['진료과목코드'].values,\n","        'Predicted_Dept': dept_predictions,\n","        'Original_Disease': test_df['주상병코드'].values,\n","        'Predicted_Disease': disease_predictions\n","    })\n","\n","    # 진료과목 평가\n","    dept_metrics = evaluate_multiclass(\n","        results_df['Original_Dept'],\n","        results_df['Predicted_Dept'],\n","        prefix='dept_'\n","    )\n","\n","    # 주상병 평가\n","    disease_metrics = evaluate_multiclass(\n","        results_df['Original_Disease'],\n","        results_df['Predicted_Disease'],\n","        prefix='disease_'\n","    )\n","\n","    # 결과 저장\n","    results_df.to_csv('prediction_results.csv', index=False)\n","\n","    # 메트릭 출력\n","    print(\"\\n=== Final Results ===\")\n","    print(\"\\n진료과목코드 예측 성능:\")\n","    for metric, value in dept_metrics.items():\n","        print(f\"{metric}: {value:.4f}\")\n","\n","    print(\"\\n주상병코드 예측 성능:\")\n","    for metric, value in disease_metrics.items():\n","        print(f\"{metric}: {value:.4f}\")\n","\n","    # 메트릭 저장\n","    metrics_df = pd.DataFrame({\n","        **dept_metrics,\n","        **disease_metrics\n","    }, index=[0])\n","    metrics_df.to_csv('evaluation_metrics.csv', index=False)\n","\n","    return results_df, {**dept_metrics, **disease_metrics}"],"metadata":{"id":"nx6oyJ1jb1Ny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_multiclass(y_true, y_pred, prefix=''):\n","    \"\"\"\n","    다중분류 평가 메트릭 계산\n","    \"\"\"\n","    return {\n","        f'{prefix}accuracy': accuracy_score(y_true, y_pred),\n","        f'{prefix}macro_f1': f1_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_f1': f1_score(y_true, y_pred, average='weighted'),\n","        f'{prefix}macro_precision': precision_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_precision': precision_score(y_true, y_pred, average='weighted'),\n","        f'{prefix}macro_recall': recall_score(y_true, y_pred, average='macro'),\n","        f'{prefix}weighted_recall': recall_score(y_true, y_pred, average='weighted')\n","    }"],"metadata":{"id":"jZVXxq0rcsBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_and_analyze_results(df, dept_predictions, disease_predictions):\n","    \"\"\"\n","    예측 결과 저장 및 분석\n","    \"\"\"\n","    # 결과 DataFrame 생성\n","    results_df = pd.DataFrame({\n","        'Original_Dept': df.loc[int(len(df)*0.8):, '진료과목코드'],\n","        'Predicted_Dept': dept_predictions,\n","        'Original_Disease': df.loc[int(len(df)*0.8):, '주상병코드'],\n","        'Predicted_Disease': disease_predictions\n","    })\n","\n","    # 진료과목 예측 평가\n","    dept_metrics = evaluate_multiclass(\n","        results_df['Original_Dept'],\n","        results_df['Predicted_Dept'],\n","        prefix='dept_'\n","    )\n","\n","    # 주상병 예측 평가\n","    disease_metrics = evaluate_multiclass(\n","        results_df['Original_Disease'],\n","        results_df['Predicted_Disease'],\n","        prefix='disease_'\n","    )\n","\n","    # 오류 분석\n","    dept_errors = results_df[results_df['Original_Dept'] != results_df['Predicted_Dept']]\n","    disease_errors = results_df[results_df['Original_Disease'] != results_df['Predicted_Disease']]\n","\n","    # 결과 저장\n","    results_df.to_csv('prediction_results.csv', index=False)\n","\n","    # 메트릭 출력\n","    print(\"\\n=== 진료과목 예측 성능 ===\")\n","    for metric, value in dept_metrics.items():\n","        print(f\"{metric}: {value:.4f}\")\n","\n","    print(\"\\n=== 주상병 예측 성능 ===\")\n","    for metric, value in disease_metrics.items():\n","        print(f\"{metric}: {value:.4f}\")\n","\n","    print(f\"\\n=== 오류 분석 ===\")\n","    print(f\"진료과목 오류 케이스 수: {len(dept_errors)}\")\n","    print(f\"주상병 오류 케이스 수: {len(disease_errors)}\")\n","\n","    # 전체 메트릭 저장\n","    metrics_df = pd.DataFrame({\n","        **dept_metrics,\n","        **disease_metrics\n","    }, index=[0])\n","    metrics_df.to_csv('evaluation_metrics.csv', index=False)\n","\n","    return results_df, dept_metrics, disease_metrics\n"],"metadata":{"id":"S84kR0fXcu7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    # 데이터 로드\n","    df = pd.read_csv(\"/content/drive/MyDrive/데이터/medical_data.csv\", encoding = 'utf-8')\n","\n","    # GPU 메모리 정리\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # 2단계 예측 실행\n","    predictor = TwoStagePredictor()\n","    dept_predictions, disease_predictions = predictor.predict(df)\n","\n","    # 결과 저장\n","    results_df = pd.DataFrame({\n","        'Original_Dept': df.loc[int(len(df)*0.8):, '진료과목코드'],\n","        'Predicted_Dept': dept_predictions,\n","        'Original_Disease': df.loc[int(len(df)*0.8):, '주상병코드'],\n","        'Predicted_Disease': disease_predictions\n","    })\n","\n","    results_df.to_csv('prediction_results.csv', index=False)\n","    return results_df\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d465cefa40b64186834b3ecb7cb57865","ee677969d09b4d8eba6b69dd1c856460","8195454d50b0478e98bb179072cab378","1e53e20c75104f4f8e0edb2602a66239","149976dacf8a443fa27e56e29d494b6e","4d3b0adb932c4bf387f8707eb1175518","1b961483f9e249cbb85fc230b72e7810","7aee1bc6aeb74735862c394a5fba42f0","a89926397ac5440e893c69f53681cb92","2de6f0c736984eccba1aba4f739e9b0d","f940ebfe16da49168d66ef75dded1471","c5312609a32f4e339d0729c483da8251","483d34cc49ca49e1a70a190c7a95abf7","2810fe61f287441c8f878c16d0884e7a","e3eb5a59dfb2427e92a86fbc9da6c06c","b926dedf4f6940369b5c5af0ed87c495","93aa266e64864f55ae808a18aa5c0cdb","1b621072403e405c9d45d0c1db4e74be","44650ea298fa4a9b9114d897841a1849","4f2b61d046ab46d48aaebb6a960c3cee","87a91b26d4264324be3a956263a76a9c","d50bd60ea4504339b4c064af0f97d3b1","b0b7c8b7157d40e2b1908a0d1c4ef201","f05bc94bb1b146b0a298fb4604a99688","92bf9653c2c2475f905495ed266422b8","0e1c0354a8e44fd9a39b9f43b90d7e88","23ceaafdc4084b5bbb3071140d3b3fbd","ce336c2647a84010a6aa2f46cf17757a","6b30cd5a3dbc45bd9c6c2aa4cd3ded7c","580bbacbe4b34ace8a8de2c0819fe182","11da50eaf1a84e0292ce0e57ee0d00fe","cef67c120962422895eee952e243bf67","8e99d0f6cea844f5ae87bb2290419801","66ae33c098d04002b912b0d493dace1a","a33b07d372614248b27cd4fba0e6989b","64f48574dc3c4bdca06c9acbb096d77f","ff17bc72d15049b99a38697551b73b5a","10f7806337a84c49906c07e57e2c82dd","4553f783cd984bafab323093b81efd1b","bc9aa4598e834341a76602f59908a143","3092d007bfd34a21a8da66b08fe10ea5","651192226e08466a83a9ebd6d6b104a4","ad626efc94854644a8d682b1e056113e","ce10f2542509484ca5c62b463ff7fe90","632d7f79f0b141b48648156af1ea5b2d","45b9503cb64e4b1bac8b39e2cc03b47b","2f7507c191e54cc2803dbc45a8d1bd73","e5e92c80fde5432398c820600108fc35","2823564c06ee48c1b59a4898520ca2e9","438b7761d5154bbeb30f41a355f9fd4c","985f56f559874f89b2a3490ed59a6a36","bcf9300731324b18a6eca6551640a7de","4653221b8a0b4b04a3fe2ac150c8b207","95f483b793884abe9ee2353efee34360","e676076a308143fabc27282197856129"]},"id":"nhB_HQudb7Uo","executionInfo":{"status":"error","timestamp":1736438964940,"user_tz":-540,"elapsed":819012,"user":{"displayName":"강남대연구실","userId":"13253583547600508252"}},"outputId":"dd4088a3-cece-4b43-c80b-8effb62f6d43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Stage 1: 진료과목코드 예측 ===\n"]},{"output_type":"stream","name":"stderr","text":["\rStage 1 Processing:   0%|                                                            | 0/2 [00:00<?]"]},{"output_type":"stream","name":"stdout","text":["\n","Processing Stage 1 Text Data with KM-BERT...\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d465cefa40b64186834b3ecb7cb57865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5312609a32f4e339d0729c483da8251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/104k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b7c8b7157d40e2b1908a0d1c4ef201"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66ae33c098d04002b912b0d493dace1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/395M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"632d7f79f0b141b48648156af1ea5b2d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at madatnlp/km-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/5 [Train]: 100%|███████████████████████████| 1223/1223 [12:22<00:00,  1.65it/s, loss=2.0221]\n","Stage 1 Processing:  50%|████████████████████████████                            | 1/2 [13:34<13:34]"]},{"output_type":"stream","name":"stdout","text":["\n","Processing Stage 1 Tabular Data...\n"]},{"output_type":"stream","name":"stderr","text":["모델 학습 중:   0%|                                            | 0/3 [00:00<?, ?it/s, model=xgboost]"]},{"output_type":"stream","name":"stdout","text":["[0]\tvalidation_0-mlogloss:nan\n","[1]\tvalidation_0-mlogloss:nan\n","[2]\tvalidation_0-mlogloss:nan\n","[3]\tvalidation_0-mlogloss:nan\n","[4]\tvalidation_0-mlogloss:nan\n","[5]\tvalidation_0-mlogloss:nan\n","[6]\tvalidation_0-mlogloss:nan\n","[7]\tvalidation_0-mlogloss:nan\n","[8]\tvalidation_0-mlogloss:nan\n","[9]\tvalidation_0-mlogloss:nan\n","[10]\tvalidation_0-mlogloss:nan\n","[11]\tvalidation_0-mlogloss:nan\n","[12]\tvalidation_0-mlogloss:nan\n","[13]\tvalidation_0-mlogloss:nan\n","[14]\tvalidation_0-mlogloss:nan\n","[15]\tvalidation_0-mlogloss:nan\n","[16]\tvalidation_0-mlogloss:nan\n","[17]\tvalidation_0-mlogloss:nan\n","[18]\tvalidation_0-mlogloss:nan\n","[19]\tvalidation_0-mlogloss:nan\n","[20]\tvalidation_0-mlogloss:nan\n","[21]\tvalidation_0-mlogloss:nan\n","[22]\tvalidation_0-mlogloss:nan\n","[23]\tvalidation_0-mlogloss:nan\n","[24]\tvalidation_0-mlogloss:nan\n","[25]\tvalidation_0-mlogloss:nan\n","[26]\tvalidation_0-mlogloss:nan\n","[27]\tvalidation_0-mlogloss:nan\n","[28]\tvalidation_0-mlogloss:nan\n","[29]\tvalidation_0-mlogloss:nan\n","[30]\tvalidation_0-mlogloss:nan\n","[31]\tvalidation_0-mlogloss:nan\n","[32]\tvalidation_0-mlogloss:nan\n","[33]\tvalidation_0-mlogloss:nan\n","[34]\tvalidation_0-mlogloss:nan\n","[35]\tvalidation_0-mlogloss:nan\n","[36]\tvalidation_0-mlogloss:nan\n","[37]\tvalidation_0-mlogloss:nan\n","[38]\tvalidation_0-mlogloss:nan\n","[39]\tvalidation_0-mlogloss:nan\n","[40]\tvalidation_0-mlogloss:nan\n","[41]\tvalidation_0-mlogloss:nan\n","[42]\tvalidation_0-mlogloss:nan\n","[43]\tvalidation_0-mlogloss:nan\n","[44]\tvalidation_0-mlogloss:nan\n","[45]\tvalidation_0-mlogloss:nan\n","[46]\tvalidation_0-mlogloss:nan\n","[47]\tvalidation_0-mlogloss:nan\n","[48]\tvalidation_0-mlogloss:nan\n","[49]\tvalidation_0-mlogloss:nan\n","[50]\tvalidation_0-mlogloss:nan\n","[51]\tvalidation_0-mlogloss:nan\n","[52]\tvalidation_0-mlogloss:nan\n","[53]\tvalidation_0-mlogloss:nan\n","[54]\tvalidation_0-mlogloss:nan\n","[55]\tvalidation_0-mlogloss:nan\n","[56]\tvalidation_0-mlogloss:nan\n","[57]\tvalidation_0-mlogloss:nan\n","[58]\tvalidation_0-mlogloss:nan\n","[59]\tvalidation_0-mlogloss:nan\n","[60]\tvalidation_0-mlogloss:nan\n","[61]\tvalidation_0-mlogloss:nan\n","[62]\tvalidation_0-mlogloss:nan\n","[63]\tvalidation_0-mlogloss:nan\n","[64]\tvalidation_0-mlogloss:nan\n","[65]\tvalidation_0-mlogloss:nan\n","[66]\tvalidation_0-mlogloss:nan\n","[67]\tvalidation_0-mlogloss:nan\n","[68]\tvalidation_0-mlogloss:nan\n","[69]\tvalidation_0-mlogloss:nan\n","[70]\tvalidation_0-mlogloss:nan\n","[71]\tvalidation_0-mlogloss:nan\n","[72]\tvalidation_0-mlogloss:nan\n","[73]\tvalidation_0-mlogloss:nan\n","[74]\tvalidation_0-mlogloss:nan\n","[75]\tvalidation_0-mlogloss:nan\n","[76]\tvalidation_0-mlogloss:nan\n","[77]\tvalidation_0-mlogloss:nan\n","[78]\tvalidation_0-mlogloss:nan\n","[79]\tvalidation_0-mlogloss:nan\n","[80]\tvalidation_0-mlogloss:nan\n","[81]\tvalidation_0-mlogloss:nan\n","[82]\tvalidation_0-mlogloss:nan\n","[83]\tvalidation_0-mlogloss:nan\n","[84]\tvalidation_0-mlogloss:nan\n","[85]\tvalidation_0-mlogloss:nan\n","[86]\tvalidation_0-mlogloss:nan\n","[87]\tvalidation_0-mlogloss:nan\n","[88]\tvalidation_0-mlogloss:nan\n","[89]\tvalidation_0-mlogloss:nan\n","[90]\tvalidation_0-mlogloss:nan\n","[91]\tvalidation_0-mlogloss:nan\n","[92]\tvalidation_0-mlogloss:nan\n","[93]\tvalidation_0-mlogloss:nan\n","[94]\tvalidation_0-mlogloss:nan\n","[95]\tvalidation_0-mlogloss:nan\n","[96]\tvalidation_0-mlogloss:nan\n","[97]\tvalidation_0-mlogloss:nan\n","[98]\tvalidation_0-mlogloss:nan\n","[99]\tvalidation_0-mlogloss:nan\n","[100]\tvalidation_0-mlogloss:nan\n","[101]\tvalidation_0-mlogloss:nan\n","[102]\tvalidation_0-mlogloss:nan\n","[103]\tvalidation_0-mlogloss:nan\n","[104]\tvalidation_0-mlogloss:nan\n","[105]\tvalidation_0-mlogloss:nan\n","[106]\tvalidation_0-mlogloss:nan\n","[107]\tvalidation_0-mlogloss:nan\n","[108]\tvalidation_0-mlogloss:nan\n","[109]\tvalidation_0-mlogloss:nan\n","[110]\tvalidation_0-mlogloss:nan\n","[111]\tvalidation_0-mlogloss:nan\n","[112]\tvalidation_0-mlogloss:nan\n","[113]\tvalidation_0-mlogloss:nan\n","[114]\tvalidation_0-mlogloss:nan\n","[115]\tvalidation_0-mlogloss:nan\n","[116]\tvalidation_0-mlogloss:nan\n","[117]\tvalidation_0-mlogloss:nan\n","[118]\tvalidation_0-mlogloss:nan\n","[119]\tvalidation_0-mlogloss:nan\n","[120]\tvalidation_0-mlogloss:nan\n","[121]\tvalidation_0-mlogloss:nan\n","[122]\tvalidation_0-mlogloss:nan\n","[123]\tvalidation_0-mlogloss:nan\n","[124]\tvalidation_0-mlogloss:nan\n","[125]\tvalidation_0-mlogloss:nan\n","[126]\tvalidation_0-mlogloss:nan\n","[127]\tvalidation_0-mlogloss:nan\n","[128]\tvalidation_0-mlogloss:nan\n","[129]\tvalidation_0-mlogloss:nan\n","[130]\tvalidation_0-mlogloss:nan\n","[131]\tvalidation_0-mlogloss:nan\n","[132]\tvalidation_0-mlogloss:nan\n","[133]\tvalidation_0-mlogloss:nan\n","[134]\tvalidation_0-mlogloss:nan\n","[135]\tvalidation_0-mlogloss:nan\n","[136]\tvalidation_0-mlogloss:nan\n","[137]\tvalidation_0-mlogloss:nan\n","[138]\tvalidation_0-mlogloss:nan\n","[139]\tvalidation_0-mlogloss:nan\n","[140]\tvalidation_0-mlogloss:nan\n","[141]\tvalidation_0-mlogloss:nan\n","[142]\tvalidation_0-mlogloss:nan\n","[143]\tvalidation_0-mlogloss:nan\n","[144]\tvalidation_0-mlogloss:nan\n","[145]\tvalidation_0-mlogloss:nan\n","[146]\tvalidation_0-mlogloss:nan\n","[147]\tvalidation_0-mlogloss:nan\n","[148]\tvalidation_0-mlogloss:nan\n","[149]\tvalidation_0-mlogloss:nan\n","[150]\tvalidation_0-mlogloss:nan\n","[151]\tvalidation_0-mlogloss:nan\n","[152]\tvalidation_0-mlogloss:nan\n","[153]\tvalidation_0-mlogloss:nan\n","[154]\tvalidation_0-mlogloss:nan\n","[155]\tvalidation_0-mlogloss:nan\n","[156]\tvalidation_0-mlogloss:nan\n","[157]\tvalidation_0-mlogloss:nan\n","[158]\tvalidation_0-mlogloss:nan\n","[159]\tvalidation_0-mlogloss:nan\n","[160]\tvalidation_0-mlogloss:nan\n","[161]\tvalidation_0-mlogloss:nan\n","[162]\tvalidation_0-mlogloss:nan\n","[163]\tvalidation_0-mlogloss:nan\n","[164]\tvalidation_0-mlogloss:nan\n","[165]\tvalidation_0-mlogloss:nan\n","[166]\tvalidation_0-mlogloss:nan\n","[167]\tvalidation_0-mlogloss:nan\n","[168]\tvalidation_0-mlogloss:nan\n","[169]\tvalidation_0-mlogloss:nan\n","[170]\tvalidation_0-mlogloss:nan\n","[171]\tvalidation_0-mlogloss:nan\n","[172]\tvalidation_0-mlogloss:nan\n","[173]\tvalidation_0-mlogloss:nan\n","[174]\tvalidation_0-mlogloss:nan\n","[175]\tvalidation_0-mlogloss:nan\n","[176]\tvalidation_0-mlogloss:nan\n","[177]\tvalidation_0-mlogloss:nan\n","[178]\tvalidation_0-mlogloss:nan\n","[179]\tvalidation_0-mlogloss:nan\n","[180]\tvalidation_0-mlogloss:nan\n","[181]\tvalidation_0-mlogloss:nan\n","[182]\tvalidation_0-mlogloss:nan\n","[183]\tvalidation_0-mlogloss:nan\n","[184]\tvalidation_0-mlogloss:nan\n","[185]\tvalidation_0-mlogloss:nan\n","[186]\tvalidation_0-mlogloss:nan\n","[187]\tvalidation_0-mlogloss:nan\n","[188]\tvalidation_0-mlogloss:nan\n","[189]\tvalidation_0-mlogloss:nan\n","[190]\tvalidation_0-mlogloss:nan\n","[191]\tvalidation_0-mlogloss:nan\n","[192]\tvalidation_0-mlogloss:nan\n","[193]\tvalidation_0-mlogloss:nan\n","[194]\tvalidation_0-mlogloss:nan\n","[195]\tvalidation_0-mlogloss:nan\n","[196]\tvalidation_0-mlogloss:nan\n","[197]\tvalidation_0-mlogloss:nan\n","[198]\tvalidation_0-mlogloss:nan\n","[199]\tvalidation_0-mlogloss:nan\n"]},{"output_type":"stream","name":"stderr","text":["모델 학습 중:  33%|███████████▋                       | 1/3 [00:04<00:08,  4.01s/it, model=lightgbm]\n","Stage 1 Processing:  50%|████████████████████████████                            | 1/2 [13:38<13:38]\n"]},{"output_type":"error","ename":"ValueError","evalue":"Input data must be 2 dimensional and non empty.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-6a95ea967604>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-6a95ea967604>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 2단계 예측 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoStagePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdept_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisease_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 결과 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-fce9a4188688>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, df, test_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Tabular 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             stage1_tabular_preds = self._get_tabular_predictions(\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'진료과목코드'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-fce9a4188688>\u001b[0m in \u001b[0;36m_get_tabular_predictions\u001b[0;34m(self, df, labels, train_idx, is_stage1, position)\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         return model.train_and_predict(\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-0477cac31955>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m(self, train_data, train_labels, val_data, position)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mval_labels_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 model.fit(\n\u001b[0m\u001b[1;32m     88\u001b[0m                     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1285\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_valid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_valid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36madd_valid\u001b[0;34m(self, data, name)\u001b[0m\n\u001b[1;32m   4037\u001b[0m             _LIB.LGBM_BoosterAddValidData(\n\u001b[1;32m   4038\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4039\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4040\u001b[0m             )\n\u001b[1;32m   4041\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2523\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m                     \u001b[0;31m# create valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                     self._lazy_init(\n\u001b[0m\u001b[1;32m   2526\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m                         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m             data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n\u001b[0m\u001b[1;32m   2107\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    812\u001b[0m ) -> Tuple[np.ndarray, List[str], Union[List[str], List[int]], List[List]]:\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input data must be 2 dimensional and non empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;31m# take shallow copy in case we modify categorical columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."]}]},{"cell_type":"markdown","source":["# 구현 완료"],"metadata":{"id":"hKJ52HdzY36V"}},{"cell_type":"code","source":["import re\n","\n","# 데이터 전처리 및 준비\n","def preprocess_data(data):\n","    data.dropna(subset=['증상', '진료과목코드', '주상병코드'], inplace=True)\n","    return data\n","\n","def clean_text(text):\n","    text = text.lower()  # 소문자 변환\n","    text = re.sub(r\"[^가-힣a-zA-Z0-9\\\\s]\", \"\", text)  # 특수문자 제거\n","    text = re.sub(r\"\\\\s+\", \" \", text).strip()  # 공백 정리\n","    return text\n","\n","# Custom Dataset 정의\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=512):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        tokens = self.tokenizer(\n","            text,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\",\n","            max_length=self.max_length\n","        )\n","        return {\n","            'input_ids': tokens['input_ids'].squeeze(0),\n","            'attention_mask': tokens['attention_mask'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","# KM-BERT 임베딩 함수 (Batch 처리)\n","def get_embeddings_with_dataset(dataset, model, batch_size=64, num_workers=4):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","    embeddings = []\n","\n","    for batch in tqdm(dataloader, desc=\"Generating embeddings\"):\n","        input_ids = batch[\"input_ids\"].squeeze(1).to(device)\n","        attention_mask = batch[\"attention_mask\"].squeeze(1).to(device)\n","        with torch.no_grad():\n","            output = model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :].cpu().numpy()\n","        embeddings.append(output)\n","\n","    return np.vstack(embeddings)\n","\n","# 모델 학습 및 평가 클래스 정의\n","class ModelTrainer:\n","    def __init__(self, model, train_loader, val_loader, test_loader, device, num_classes, num_epochs=10):\n","        self.model = model\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","        self.num_classes = num_classes\n","        self.num_epochs = num_epochs\n","\n","        # Optimizer and Scheduler\n","        self.optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","        num_training_steps = len(train_loader) * self.num_epochs\n","        num_warmup_steps = num_training_steps // 10\n","        self.scheduler = get_scheduler(\n","            \"linear\",\n","            optimizer=self.optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps\n","        )\n","\n","        # Loss function\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def train_epoch(self):\n","        \"\"\"한 에폭의 학습을 수행하는 메서드\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        progress_bar = tqdm(self.train_loader, desc=\"Training\")\n","        for batch in progress_bar:\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch['attention_mask'].to(self.device)\n","            labels = batch['label'].to(self.device)\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            loss = self.criterion(logits, labels)\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","            self.optimizer.step()\n","            self.scheduler.step()\n","\n","            total_loss += loss.item()\n","            preds = torch.argmax(logits, dim=1).cpu().numpy()\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n","\n","        epoch_loss = total_loss / len(self.train_loader)\n","        epoch_accuracy = accuracy_score(all_labels, all_preds)\n","        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","        return {\n","            'loss': epoch_loss,\n","            'accuracy': epoch_accuracy,\n","            'f1': epoch_f1\n","        }\n","\n","    def evaluate(self, dataloader, mode='val'):\n","        \"\"\"Validation 또는 Test 평가 메서드\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for batch in tqdm(dataloader, desc=f\"Evaluating ({mode})\"):\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                labels = batch['label'].to(self.device)\n","\n","                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","                logits = outputs.logits\n","                loss = self.criterion(logits, labels)\n","\n","                total_loss += loss.item()\n","                preds = torch.argmax(logits, dim=1)\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = accuracy_score(all_labels, all_preds)\n","        f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","        metrics = {\n","            f'{mode}_loss': avg_loss,\n","            f'{mode}_accuracy': accuracy,\n","            f'{mode}_f1': f1\n","        }\n","\n","        return metrics\n","\n","    def train(self):\n","        \"\"\"전체 학습 수행\"\"\"\n","        for epoch in range(self.num_epochs):\n","            print(f\"\\nEpoch {epoch + 1}/{self.num_epochs}\")\n","\n","            # Training\n","            train_metrics = self.train_epoch()\n","            print(f\"Training metrics: {train_metrics}\")\n","\n","            # Validation\n","            val_metrics = self.evaluate(self.val_loader, mode='val')\n","            print(f\"Validation metrics: {val_metrics}\")\n","\n","        # 최종 Test 평가\n","        test_metrics = self.evaluate(self.test_loader, mode='test')\n","        print(\"\\nFinal Test Results:\", test_metrics)\n","\n","        return test_metrics"],"metadata":{"id":"YQlED7xktI9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n","\n","data = preprocess_data(df)\n","\n","# Train-Test Split\n","train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# 라벨 인코딩\n","label_encoder_diagnosis = LabelEncoder()\n","label_encoder_code = LabelEncoder()\n","train_data['진료과목코드'] = label_encoder_diagnosis.fit_transform(train_data['진료과목코드'])\n","test_data['진료과목코드'] = label_encoder_diagnosis.transform(test_data['진료과목코드'])\n","train_data['주상병코드'] = label_encoder_code.fit_transform(train_data['주상병코드'])\n","test_data['주상병코드'] = label_encoder_code.transform(test_data['주상병코드'])"],"metadata":{"id":"5EkZ-yOnM7_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#gpu 초기화\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"Wq7b1yvUCsNB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# KM-BERT 모델 및 토크나이저 준비\n","tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-BERT-char16424\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"madatnlp/km-bert\", num_labels=len(label_encoder_diagnosis.classes_))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# 텍스트 데이터셋 및 데이터로더\n","train_dataset = TextDataset(train_data['증상'].tolist(), train_data['진료과목코드'].tolist(), tokenizer)\n","test_dataset = TextDataset(test_data['증상'].tolist(), test_data['진료과목코드'].tolist(), tokenizer)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# 데이터 확인\n","for batch in train_dataloader:\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    print(f\"KM-BERT Input IDs shape: {input_ids.shape}\")\n","    print(f\"KM-BERT Attention Mask shape: {attention_mask.shape}\")\n","    print(f\"KM-BERT Labels shape: {labels.shape}\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAbyWCuCIxo7","executionInfo":{"status":"ok","timestamp":1734096053642,"user_tz":-540,"elapsed":781,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"68ea9af0-399a-4e5f-b64e-662533c6278a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at madatnlp/km-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["KM-BERT Input IDs shape: torch.Size([64, 512])\n","KM-BERT Attention Mask shape: torch.Size([64, 512])\n","KM-BERT Labels shape: torch.Size([64])\n"]}]},{"cell_type":"code","source":["# ModelTrainer 초기화 및 학습\n","trainer = ModelTrainer(\n","    model=model,\n","    train_loader=train_dataloader,\n","    val_loader=test_dataloader,\n","    test_loader=test_dataloader,\n","    device=device,\n","    num_classes=len(label_encoder_diagnosis.classes_),\n","    num_epochs=1\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0l_bIzNI2Bz","executionInfo":{"status":"ok","timestamp":1734096915128,"user_tz":-540,"elapsed":843581,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"a1496bdd-1969-4247-d641-59c9d29825a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/1\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 612/612 [12:00<00:00,  1.18s/it, loss=2.2825]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2933085967902263, 'accuracy': 0.26773484616170906, 'f1': 0.22950174206191673}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 153/153 [01:01<00:00,  2.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.1887322812298544, 'val_accuracy': 0.29479709700500867, 'val_f1': 0.23644439492580255}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (test): 100%|██████████| 153/153 [01:01<00:00,  2.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Final Test Results: {'test_loss': 2.1887322812298544, 'test_accuracy': 0.29479709700500867, 'test_f1': 0.23644439492580255}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_loss': 2.1887322812298544,\n"," 'test_accuracy': 0.29479709700500867,\n"," 'test_f1': 0.23644439492580255}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# KM-BERT 전체 데이터셋 예측\n","def predict_kmbert(model, dataloader, device):\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Predicting with KM-BERT\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            probs = torch.softmax(logits, dim=1).cpu().numpy()\n","            predictions.append(probs)\n","    return np.vstack(predictions)\n","\n","kmbert_train_probs = predict_kmbert(model, train_dataloader, device)\n","kmbert_test_probs = predict_kmbert(model, test_dataloader, device)\n","\n","# KM-BERT 출력 크기 확인\n","print(f\"KM-BERT Train Probs Shape: {kmbert_train_probs.shape}\")\n","print(f\"KM-BERT Test Probs Shape: {kmbert_test_probs.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOy1mJPaM-ec","executionInfo":{"status":"ok","timestamp":1734097232283,"user_tz":-540,"elapsed":307029,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"bf87629a-4947-4b3d-acd4-e8c88bffb516"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Predicting with KM-BERT: 100%|██████████| 612/612 [04:05<00:00,  2.49it/s]\n","Predicting with KM-BERT: 100%|██████████| 153/153 [01:01<00:00,  2.50it/s]"]},{"output_type":"stream","name":"stdout","text":["KM-BERT Train Probs Shape: (39132, 18)\n","KM-BERT Test Probs Shape: (9783, 18)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 1차 분류: XGBoost 학습\n","# 정형 데이터 준비\n","X_train_tabular = train_data[['성별코드', '연령대코드', '요양일수', '입내원일수', '총처방일수']]\n","X_test_tabular = test_data[['성별코드', '연령대코드', '요양일수', '입내원일수', '총처방일수']]\n","\n","one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","scaler = StandardScaler()\n","\n","X_train_tabular = scaler.fit_transform(one_hot_encoder.fit_transform(X_train_tabular))\n","X_test_tabular = scaler.transform(one_hot_encoder.transform(X_test_tabular))\n","\n","# 1차 분류: XGBoost\n","xgb_model = XGBClassifier()\n","xgb_model.fit(X_train_tabular, train_data['진료과목코드'])\n","xgb_train_probs = xgb_model.predict_proba(X_train_tabular)\n","xgb_test_probs = xgb_model.predict_proba(X_test_tabular)\n","\n","# XGBoost 출력 크기 확인\n","print(f\"XGBoost Train Probs Shape: {xgb_train_probs.shape}\")\n","print(f\"XGBoost Test Probs Shape: {xgb_test_probs.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJYn8CNhNCJZ","executionInfo":{"status":"ok","timestamp":1734097247725,"user_tz":-540,"elapsed":8470,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"3be43b8e-0f43-4639-aca8-cd09f18b99a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost Train Probs Shape: (39132, 18)\n","XGBoost Test Probs Shape: (9783, 18)\n"]}]},{"cell_type":"code","source":["# 1차 분류: Stack Ensemble\n","stack_train_input = np.hstack([kmbert_train_probs, xgb_train_probs])\n","stack_test_input = np.hstack([kmbert_test_probs, xgb_test_probs])\n","\n","# Stack Ensemble 입력 크기 확인\n","print(f\"Stack Train Input Shape: {stack_train_input.shape}\")\n","print(f\"Stack Test Input Shape: {stack_test_input.shape}\")\n","\n","stack_model = XGBClassifier()\n","stack_model.fit(stack_train_input, train_data['진료과목코드'])\n","stack_preds = stack_model.predict(stack_test_input)\n","\n","# 1차 분류 성능 평가\n","print(f\"1차 분류 Accuracy: {accuracy_score(test_data['진료과목코드'], stack_preds):.4f}\")\n","# print(\"Classification Report for 1차 분류:\")\n","# print(classification_report(test_data['진료과목코드'], stack_preds, target_names=label_encoder_diagnosis.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3lfV8s_NGPu","executionInfo":{"status":"ok","timestamp":1734097254365,"user_tz":-540,"elapsed":4605,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"a4a38fac-d3d7-4fb8-ade6-e8706199035b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stack Train Input Shape: (39132, 36)\n","Stack Test Input Shape: (9783, 36)\n","1차 분류 Accuracy: 0.2540\n"]}]},{"cell_type":"code","source":["# 2차 분류: 주상병코드 예측\n","stack_input_2_train = np.hstack([stack_train_input, train_data['진료과목코드'].values.reshape(-1, 1)])\n","stack_input_2_test = np.hstack([stack_test_input, test_data['진료과목코드'].values.reshape(-1, 1)])\n","\n","second_model = XGBClassifier()\n","second_model.fit(stack_input_2_train, train_data['주상병코드'])\n","y_second_pred = second_model.predict(stack_input_2_test)\n","\n","print(f\"2차 분류 Accuracy: {accuracy_score(test_data['주상병코드'], y_second_pred):.4f}\")\n","# print(\"Classification Report for 2차 분류:\")\n","# print(classification_report(test_data['주상병코드'], y_second_pred, target_names=label_encoder_code.classes_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HdMIyIZNEhN","executionInfo":{"status":"ok","timestamp":1734097269024,"user_tz":-540,"elapsed":9809,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"5f97d622-7419-4479-e753-81672223a55f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2차 분류 Accuracy: 0.3609\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filekmbert_finetuned_model.pt\")\n","\n","# 스택 모델 및 2차 모델 저장\n","joblib.dump(stack_model, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filestack_model_1.pkl\")\n","joblib.dump(second_model, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filestack_model_2.pkl\")\n","\n","# XGB 모델 저장 (1차 분류용)\n","joblib.dump(xgb_model, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filexgb_model_for_1st_stage.pkl\")\n","\n","# 인코더 및 스케일러 저장\n","joblib.dump(label_encoder_diagnosis, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filelabel_encoder_diagnosis.pkl\")\n","joblib.dump(label_encoder_code, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filelabel_encoder_code.pkl\")\n","joblib.dump(one_hot_encoder, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_fileonehot_encoder.pkl\")\n","joblib.dump(scaler, \"/content/drive/MyDrive/University/4-2/정보기술학회/data/model_filescaler.pkl\")\n","\n","print(\"모델 및 인코더 저장 완료.\")"],"metadata":{"id":"QU7XEoOpT3Qi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734097274132,"user_tz":-540,"elapsed":1402,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"77623c08-d6ac-4b19-9cb2-4114b760769a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["모델 및 인코더 저장 완료.\n"]}]}]}