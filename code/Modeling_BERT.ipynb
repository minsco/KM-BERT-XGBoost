{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sA2D8yD-CeEF"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import warnings\n","import logging\n","from pathlib import Path\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","import torch.nn as nn\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n","from tqdm import tqdm\n","import json\n","from datetime import datetime\n","import gc\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.utils.checkpoint import checkpoint\n","import torch.distributed as dist\n","from torch.nn.parallel import DistributedDataParallel\n","import gc\n","from torch.cuda import Event"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/University/4-2/정보기술학회/data/medical_data.csv\", encoding = \"utf-8\")\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KsmizxUQC6a_","executionInfo":{"status":"ok","timestamp":1733188755043,"user_tz":-540,"elapsed":12636,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"4c47bc83-df6c-49b6-a09f-efabc72e085c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2891197, 11)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 진료과목코드별 빈도수 확인 및 1000개 이상인 코드만 필터링\n","dept_counts = df['진료과목코드'].value_counts()\n","valid_depts = dept_counts[dept_counts >= 1000].index.tolist()\n","\n","# 유효한 진료과목코드만 필터링\n","filtered_df = df[df['진료과목코드'].isin(valid_depts)]\n","\n","# 각 진료과목코드별로 1000개씩 샘플링\n","balanced_dfs = []\n","for dept in valid_depts:\n","    dept_sample = filtered_df[filtered_df['진료과목코드'] == dept].sample(n=1000, random_state=42)\n","    balanced_dfs.append(dept_sample)\n","\n","# 최종 균형잡힌 데이터셋 생성\n","final_df = pd.concat(balanced_dfs, ignore_index=True)\n","\n","# 결과 확인\n","print(\"최종 데이터셋 크기:\", len(final_df))\n","print(\"\\n각 진료과목코드별 샘플 수:\")\n","print(final_df['진료과목코드'].value_counts())"],"metadata":{"id":"2yYjW9_9C6mD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733188755553,"user_tz":-540,"elapsed":513,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"5a24e08c-eec2-40cd-db2f-601883bc956b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["최종 데이터셋 크기: 17000\n","\n","각 진료과목코드별 샘플 수:\n","진료과목코드\n","1     1000\n","13    1000\n","12    1000\n","11    1000\n","23    1000\n","4     1000\n","24    1000\n","2     1000\n","5     1000\n","6     1000\n","0     1000\n","21    1000\n","9     1000\n","7     1000\n","14    1000\n","10    1000\n","16    1000\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["final_df = pd.read_csv(\"/content/drive/MyDrive/University/4-2/정보기술학회/data/final_df.csv\", encoding = \"utf-8\")\n","final_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oNvEF2hEphI","executionInfo":{"status":"ok","timestamp":1733188789801,"user_tz":-540,"elapsed":306,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"7c3f997d-350d-43de-a17f-e359b6e06fde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17000, 11)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from transformers import AutoTokenizer, AutoModel\n","from torch.utils.data import Dataset, DataLoader\n","import re\n","\n","class MedicalDataPreprocessor:\n","    def __init__(self):\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"madatnlp/km-bert\")\n","\n","    def clean_text(self, text):\n","        \"\"\"의료 도메인 특성을 고려한 텍스트 전처리\"\"\"\n","        # 불필요한 특수문자 제거하되 의미있는 구분자(.,)는 보존\n","        text = re.sub(r'[^가-힣a-zA-Z0-9.,\\s]', ' ', str(text))\n","        # 중복된 공백 제거\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","        # 중복된 마침표 정리\n","        text = re.sub(r'\\.+', '.', text)\n","        return text\n","\n","    def prepare_dataset(self, df):\n","        \"\"\"데이터셋 준비\"\"\"\n","        # 텍스트 전처리\n","        df['cleaned_symptoms'] = df['증상'].apply(self.clean_text)\n","\n","        # 레이블 인코딩\n","        unique_departments = sorted(df['진료과목코드'].unique())\n","        self.dept_to_idx = {dept: idx for idx, dept in enumerate(unique_departments)}\n","        df['label'] = df['진료과목코드'].map(self.dept_to_idx)\n","\n","        # 계층화된 train/val/test 분할 (8:1:1)\n","        train_df, temp_df = train_test_split(\n","            df, test_size=0.2, stratify=df['label'], random_state=42\n","        )\n","        val_df, test_df = train_test_split(\n","            temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42\n","        )\n","\n","        return train_df, val_df, test_df\n","\n","class MedicalDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length=512):\n","        self.texts = df['cleaned_symptoms'].tolist()\n","        self.labels = df['label'].tolist()\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","\n","        # 토큰화 및 패딩\n","        encoding = self.tokenizer(\n","            text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),\n","            'attention_mask': encoding['attention_mask'].squeeze(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","def create_dataloaders(train_df, val_df, test_df, tokenizer, batch_size=64):\n","    \"\"\"데이터로더 생성\"\"\"\n","    train_dataset = MedicalDataset(train_df, tokenizer)\n","    val_dataset = MedicalDataset(val_df, tokenizer)\n","    test_dataset = MedicalDataset(test_df, tokenizer)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    return train_loader, val_loader, test_loader\n","\n","# 사용 예시\n","preprocessor = MedicalDataPreprocessor()\n","train_df, val_df, test_df = preprocessor.prepare_dataset(final_df)  # final_df는 이전 단계에서 생성한 균형잡힌 데이터셋\n","\n","train_loader, val_loader, test_loader = create_dataloaders(\n","    train_df, val_df, test_df,\n","    preprocessor.tokenizer\n",")"],"metadata":{"id":"XPBrFHjBDb8R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import AutoModel, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n","import numpy as np\n","from tqdm import tqdm\n","import wandb\n","\n","class MedicalBertClassifier(nn.Module):\n","    def __init__(self, num_classes, dropout_rate=0.3):\n","        super().__init__()\n","        # KM-BERT 모델 로드\n","        self.bert = AutoModel.from_pretrained(\"madatnlp/km-bert\")\n","\n","        # 분류를 위한 추가 레이어\n","        self.dropout = nn.Dropout(dropout_rate)\n","        hidden_size = self.bert.config.hidden_size\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_size // 2, num_classes)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        # BERT 출력\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","\n","        # 분류\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","        return logits"],"metadata":{"id":"zJvC8n7aD6O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ModelTrainer:\n","    def __init__(self, model, train_loader, val_loader, test_loader, device, num_classes,\n","                 patience=3, min_delta=0.001):\n","        self.model = model\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","        self.num_classes = num_classes\n","\n","        # Early stopping parameters\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.best_val_f1 = 0\n","        self.patience_counter = 0\n","\n","        # Learning components initialization\n","        self.optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","        num_training_steps = len(train_loader) * 10\n","        num_warmup_steps = num_training_steps // 10\n","        self.scheduler = get_linear_schedule_with_warmup(\n","            self.optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps\n","        )\n","\n","        # Weights & Biases initialization\n","        wandb.init(project=\"medical-department-classification\")\n","\n","    def train_epoch(self):\n","        \"\"\"한 에폭의 학습을 수행하는 메서드\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        progress_bar = tqdm(self.train_loader, desc=\"Training\")\n","        for batch in progress_bar:\n","            # 데이터를 GPU로 이동\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch['attention_mask'].to(self.device)\n","            labels = batch['label'].to(self.device)\n","\n","            # Forward pass와 loss 계산\n","            outputs = self.model(input_ids, attention_mask)\n","            loss = F.cross_entropy(outputs, labels)\n","\n","            # Backward pass와 최적화\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","            self.optimizer.step()\n","            self.scheduler.step()\n","\n","            # 메트릭 수집\n","            total_loss += loss.item()\n","            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","            # 진행 상황 업데이트\n","            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n","\n","        # 에폭 단위 메트릭 계산\n","        epoch_loss = total_loss / len(self.train_loader)\n","        epoch_accuracy = accuracy_score(all_labels, all_preds)\n","        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","        # 메트릭을 wandb에 기록\n","        wandb.log({\n","            'train_loss': epoch_loss,\n","            'train_accuracy': epoch_accuracy,\n","            'train_f1': epoch_f1\n","        })\n","\n","        return {\n","            'loss': epoch_loss,\n","            'accuracy': epoch_accuracy,\n","            'f1': epoch_f1\n","        }\n","\n","    def evaluate(self, dataloader, mode='val'):\n","        self.model.eval()\n","        total_loss = 0\n","        all_preds = []\n","        all_labels = []\n","        all_probs = []\n","\n","        with torch.no_grad():\n","            for batch in tqdm(dataloader, desc=f\"Evaluating ({mode})\"):\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                labels = batch['label'].to(self.device)\n","\n","                outputs = self.model(input_ids, attention_mask)\n","                loss = F.cross_entropy(outputs, labels)\n","\n","                probs = F.softmax(outputs, dim=1)\n","                preds = torch.argmax(outputs, dim=1)\n","\n","                total_loss += loss.item()\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","                all_probs.extend(probs.cpu().numpy())\n","\n","        # 종합 메트릭 계산\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = accuracy_score(all_labels, all_preds)\n","        f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","        # ROC-AUC 계산 (one-vs-rest)\n","        roc_auc = roc_auc_score(\n","            np.eye(self.num_classes)[all_labels],\n","            np.array(all_probs),\n","            multi_class='ovr',\n","            average='weighted'\n","        )\n","\n","        # Confusion Matrix\n","        conf_matrix = confusion_matrix(all_labels, all_preds)\n","\n","        metrics = {\n","            f'{mode}_loss': avg_loss,\n","            f'{mode}_accuracy': accuracy,\n","            f'{mode}_f1': f1,\n","            f'{mode}_roc_auc': roc_auc\n","        }\n","\n","        # Weights & Biases에 로깅\n","        wandb.log(metrics)\n","\n","        return metrics, conf_matrix\n","\n","    def train(self, num_epochs=10):\n","        best_val_f1 = 0\n","        early_stop = False\n","\n","        for epoch in range(num_epochs):\n","            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n","\n","            # Training\n","            train_metrics = self.train_epoch()\n","            print(f\"Training metrics: {train_metrics}\")\n","\n","            # Validation\n","            val_metrics, val_conf_matrix = self.evaluate(self.val_loader, mode='val')\n","            print(f\"Validation metrics: {val_metrics}\")\n","\n","            current_val_f1 = val_metrics['val_f1']\n","\n","            # Early stopping logic\n","            if current_val_f1 > self.best_val_f1 + self.min_delta:\n","                # 성능 향상이 있는 경우\n","                self.best_val_f1 = current_val_f1\n","                self.patience_counter = 0\n","\n","                # 향상된 모델 저장\n","                torch.save(self.model.state_dict(), 'best_model.pt')\n","                print(f\"New best model saved! Validation F1: {current_val_f1:.4f}\")\n","\n","                # 모델 메타데이터 저장\n","                model_metadata = {\n","                    'epoch': epoch + 1,\n","                    'val_f1': current_val_f1,\n","                    'val_accuracy': val_metrics['val_accuracy'],\n","                    'val_loss': val_metrics['val_loss'],\n","                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","                }\n","                with open('model_metadata.json', 'w') as f:\n","                    json.dump(model_metadata, f, indent=4)\n","\n","            else:\n","                # 성능 향상이 없는 경우\n","                self.patience_counter += 1\n","                print(f\"No improvement in validation F1. Patience: {self.patience_counter}/{self.patience}\")\n","\n","                if self.patience_counter >= self.patience:\n","                    print(\"\\nEarly stopping triggered!\")\n","                    print(f\"Best validation F1: {self.best_val_f1:.4f}\")\n","                    early_stop = True\n","                    break\n","\n","            # wandb에 로깅\n","            wandb.log({\n","                'epoch': epoch + 1,\n","                'patience_counter': self.patience_counter,\n","                'best_val_f1': self.best_val_f1\n","            })\n","\n","        # 학습 완료 후 처리\n","        if early_stop:\n","            print(\"\\nTraining stopped early due to no improvement in validation F1\")\n","        else:\n","            print(\"\\nTraining completed for all epochs\")\n","\n","        # 최종 평가를 위해 best 모델 로드\n","        print(\"\\nLoading best model for final evaluation...\")\n","        self.model.load_state_dict(torch.load('best_model.pt'))\n","        test_metrics, test_conf_matrix = self.evaluate(self.test_loader, mode='test')\n","        print(\"\\nFinal Test Results:\", test_metrics)\n","\n","        return test_metrics, test_conf_matrix"],"metadata":{"id":"6xzfm0SYo8eY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 실행\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_classes = len(preprocessor.dept_to_idx)  # 이전 코드에서 정의된 preprocessor 사용\n","\n","model = MedicalBertClassifier(num_classes=num_classes).to(device)\n","trainer = ModelTrainer(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    test_loader=test_loader,\n","    device=device,\n","    num_classes=num_classes,\n","    patience=3,  # Stop if no improvement for 3 epochs\n","    min_delta=0.001  # Minimum improvement required\n",")\n","\n","test_metrics, test_conf_matrix = trainer.train(num_epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qP9qRquwo271","executionInfo":{"status":"ok","timestamp":1733186534497,"user_tz":-540,"elapsed":2531066,"user":{"displayName":"함양훈","userId":"11408684467918551547"}},"outputId":"7b2f3b0c-9d6d-42ef-db55-99c419e737b3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:1hnj0c30) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <style>\n","        .wandb-row {\n","            display: flex;\n","            flex-direction: row;\n","            flex-wrap: wrap;\n","            justify-content: flex-start;\n","            width: 100%;\n","        }\n","        .wandb-col {\n","            display: flex;\n","            flex-direction: column;\n","            flex-basis: 100%;\n","            flex: 1;\n","            padding: 10px;\n","        }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>▁▃███</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>patience_counter</td><td>▁▁▁▅█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_roc_auc</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▇████</td></tr><tr><td>train_f1</td><td>▁▇████</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▃██▅▆</td></tr><tr><td>val_loss</td><td>█▂▂▂▁▁</td></tr><tr><td>val_roc_auc</td><td>▁▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>0.23643</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>patience_counter</td><td>2</td></tr><tr><td>test_accuracy</td><td>0.28235</td></tr><tr><td>test_f1</td><td>0.23806</td></tr><tr><td>test_loss</td><td>2.21661</td></tr><tr><td>test_roc_auc</td><td>0.76511</td></tr><tr><td>train_accuracy</td><td>0.27324</td></tr><tr><td>train_f1</td><td>0.2387</td></tr><tr><td>train_loss</td><td>2.20487</td></tr><tr><td>val_accuracy</td><td>0.27765</td></tr><tr><td>val_f1</td><td>0.22624</td></tr><tr><td>val_loss</td><td>2.21298</td></tr><tr><td>val_roc_auc</td><td>0.7711</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">icy-snowflake-6</strong> at: <a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification/runs/1hnj0c30' target=\"_blank\">https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification/runs/1hnj0c30</a><br/> View project at: <a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification' target=\"_blank\">https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20241202_231343-1hnj0c30/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:1hnj0c30). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241203_000003-08o55hpe</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification/runs/08o55hpe' target=\"_blank\">kind-puddle-7</a></strong> to <a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification' target=\"_blank\">https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification/runs/08o55hpe' target=\"_blank\">https://wandb.ai/yanghoonham-kangnam-university/medical-department-classification/runs/08o55hpe</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.5803]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.6553469543725674, 'accuracy': 0.17161764705882354, 'f1': 0.15626367299149388}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.3629452034279153, 'val_accuracy': 0.2752941176470588, 'val_f1': 0.2048727895114093, 'val_roc_auc': 0.7449136029411765}\n","New best model saved! Validation F1: 0.2049\n","\n","Epoch 2/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=1.9838]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.3071634584749248, 'accuracy': 0.26323529411764707, 'f1': 0.22756081757540736}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.2662588711138123, 'val_accuracy': 0.27705882352941175, 'val_f1': 0.2094570143161646, 'val_roc_auc': 0.75823125}\n","New best model saved! Validation F1: 0.2095\n","\n","Epoch 3/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.4600]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2517077687760474, 'accuracy': 0.2701470588235294, 'f1': 0.2363241764339537}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.2369064622455173, 'val_accuracy': 0.28, 'val_f1': 0.2113294363028019, 'val_roc_auc': 0.7626194852941178}\n","New best model saved! Validation F1: 0.2113\n","\n","Epoch 4/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.2954]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2332052305830477, 'accuracy': 0.27595588235294116, 'f1': 0.24031887114133932}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.2259222489816173, 'val_accuracy': 0.2782352941176471, 'val_f1': 0.22333453148697277, 'val_roc_auc': 0.7658919117647058}\n","New best model saved! Validation F1: 0.2233\n","\n","Epoch 5/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=1.9035]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.21730607216347, 'accuracy': 0.27683823529411766, 'f1': 0.24581321509165832}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.222959845154374, 'val_accuracy': 0.27705882352941175, 'val_f1': 0.22654779796763883, 'val_roc_auc': 0.7690011029411765}\n","New best model saved! Validation F1: 0.2265\n","\n","Epoch 6/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.3131]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2127111433817186, 'accuracy': 0.27330882352941177, 'f1': 0.24191522463194506}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.218348834249708, 'val_accuracy': 0.2817647058823529, 'val_f1': 0.22248497832250033, 'val_roc_auc': 0.7687323529411765}\n","No improvement in validation F1. Patience: 1/3\n","\n","Epoch 7/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.2001]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2105909513195914, 'accuracy': 0.2716911764705882, 'f1': 0.24002198133676164}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.213340198552167, 'val_accuracy': 0.2847058823529412, 'val_f1': 0.22772377384953826, 'val_roc_auc': 0.7694687499999998}\n","New best model saved! Validation F1: 0.2277\n","\n","Epoch 8/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.2517]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.2031891547458273, 'accuracy': 0.2758088235294118, 'f1': 0.24390716247463778}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.212839192814297, 'val_accuracy': 0.28411764705882353, 'val_f1': 0.2250889510818152, 'val_roc_auc': 0.7695933823529413}\n","No improvement in validation F1. Patience: 1/3\n","\n","Epoch 9/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=1.9573]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.20091785623434, 'accuracy': 0.2757352941176471, 'f1': 0.2458459651400451}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.212196288285432, 'val_accuracy': 0.28294117647058825, 'val_f1': 0.2229444050932327, 'val_roc_auc': 0.7690988970588236}\n","No improvement in validation F1. Patience: 2/3\n","\n","Epoch 10/10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 213/213 [04:01<00:00,  1.13s/it, loss=2.3785]\n"]},{"output_type":"stream","name":"stdout","text":["Training metrics: {'loss': 2.1968427700615827, 'accuracy': 0.2757352941176471, 'f1': 0.2464425810116824}\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating (val): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'val_loss': 2.2120639041618064, 'val_accuracy': 0.28058823529411764, 'val_f1': 0.23095083495996885, 'val_roc_auc': 0.7699485294117648}\n","New best model saved! Validation F1: 0.2310\n","\n","Training completed for all epochs\n","\n","Loading best model for final evaluation...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-22-7186b53edda6>:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.model.load_state_dict(torch.load('best_model.pt'))\n","Evaluating (test): 100%|██████████| 27/27 [00:09<00:00,  2.80it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Final Test Results: {'test_loss': 2.2008956052638866, 'test_accuracy': 0.2811764705882353, 'test_f1': 0.23037198319437865, 'test_roc_auc': 0.7700801470588235}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}